{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/miquelmn/aa_2526/blob/main/07_Batch_normalization/Batch_normalization.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "</div>\n",
    "\n",
    "# Batch Normalization\n",
    "\n",
    "## Objectius\n",
    "\n",
    "En aquesta pràctica, ampliarem el treball realitzat amb AlexNet i *transfer learning*, incorporant tècniques de regularització i optimització per millorar el rendiment del model. Els objectius són:\n",
    "\n",
    "- **Implementar Batch Normalization**: afegir capes de normalització per estabilitzar i accelerar l'entrenament.\n",
    "- **Comparar resultats**: analitzar l'impacte de cada tècnica en el rendiment final del model.\n",
    "- **Optimització d'hiperparàmetres**: provar diferents configuracions per trobar la millor combinació.\n",
    "\n",
    "Aquest enfocament permetrà comprendre com les tècniques vistes a teoria milloren la generalització i eviten l'overfitting en problemes reals de classificació d'imatges.\n",
    "\n",
    "Una segona part serà emprar els nous models vists a classe de teoria.\n",
    "\n",
    "## Introducció\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "La Batch Normalization és una tècnica que normalitza les activacions de cada capa durant l'entrenament, utilitzant la mitjana i la desviació estàndard del mini-batch actual. Els seus principals avantatges són:\n",
    "\n",
    "- **Accelera l'entrenament**: permet utilitzar learning rates més alts.\n",
    "- **Redueix la sensibilitat a la inicialització**: els pesos inicials tenen menys impacte.\n",
    "- **Actua com a regularitzador**: redueix la necessitat de Dropout en alguns casos.\n",
    "- **Millora la convergència**: facilita que el model arribi a millors mínims.\n",
    "\n",
    "\n",
    "La formulació d'aquesta operació, tal com heu vist a classe de teoria, és la següent:\n",
    "\n",
    "$$ \\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$$\n",
    "\n",
    "$$ y_i = \\gamma \\hat{x}_i + \\beta, $$\n",
    "\n",
    "on $\\gamma$ i $\\beta$ són paràmetres entrenables.\n",
    "\n",
    "Per implementar-ho feim operacions diferents a entrenament i validació."
   ],
   "id": "705b437a14703a10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyBatchNorm1d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "\n",
    "        # Evitar divisió per 0\n",
    "        self.eps = eps\n",
    "\n",
    "        # Momentum\n",
    "        self.momentum = momentum\n",
    "\n",
    "        # Paràmetres aprenables: gamma (weight) i beta (bias)\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "        # Estadístiques que s’acumulen durant l’entrenament però que no són paràmetres\n",
    "        self.register_buffer(\"running_mean\", torch.zeros(num_features))\n",
    "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Calcular mitjana i variància del batch\n",
    "            batch_mean = x.mean(dim=0)\n",
    "            batch_var = x.var(dim=0, unbiased=False)\n",
    "\n",
    "            # Actualitzar estadístiques globals\n",
    "            self.running_mean =\n",
    "            self.running_var =\n",
    "\n",
    "            # Normalitzar el batch actual\n",
    "            x_hat =\n",
    "        else:\n",
    "            # En mode d’avaluació, s’usen les estadístiques acumulades\n",
    "            x_hat =\n",
    "\n",
    "        # Aplicar gamma i beta\n",
    "        y = self.gamma * x_hat + self.beta\n",
    "        return y\n"
   ],
   "id": "eeaafbfb655b8a85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
